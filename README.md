# Evaluating Machine Unlearning Algorithms for Mitigating Malicious Use and Preserving Privacy in Language Models  
### A Combined MUSE, WMDP, and TOFU Approach

---

## 📄 Overview

The project explores how **machine unlearning techniques** can reduce hazardous knowledge (e.g., instructions for biological or cyber weapons) and enhance privacy in **Large Language Models (LLMs)** by removing specific learned information efficiently, without full retraining.

This evaluation combines:

✅ **MUSE** – Machine Unlearning Six-Way Evaluation framework  
✅ **WMDP** – Weapons of Mass Destruction Proxy benchmark  
✅ **TOFU** – Task of Fictitious Unlearning for privacy simulation  

---

## 🎯 Objectives

The project aims to assess unlearning algorithms for:

- 🔥 Reducing malicious use in LLMs using **WMDP**
- 🛡️ Preserving privacy by simulating personal data removal with **TOFU**

Applying **MUSE's comprehensive six-way evaluation**, covering:

- ✅ No verbatim memorization  
- ✅ No knowledge memorization  
- ✅ No privacy leakage  
- ✅ Utility preservation  
- ✅ Scalability  
- ✅ Sustainability  

---

## 📁 Repository Under Development

The full codebase, datasets, and evaluation scripts will be organized to support experimentation and reproducibility. Stay tuned for updates.

---

