# Evaluating Machine Unlearning Algorithms for Mitigating Malicious Use and Preserving Privacy in Language Models  
### A Combined MUSE, WMDP, and TOFU Approach

---

## ğŸ“„ Overview

The project explores how **machine unlearning techniques** can reduce hazardous knowledge (e.g., instructions for biological or cyber weapons) and enhance privacy in **Large Language Models (LLMs)** by removing specific learned information efficiently, without full retraining.

This evaluation combines:

âœ… **MUSE** â€“ Machine Unlearning Six-Way Evaluation framework  
âœ… **WMDP** â€“ Weapons of Mass Destruction Proxy benchmark  
âœ… **TOFU** â€“ Task of Fictitious Unlearning for privacy simulation  

---

## ğŸ¯ Objectives

The project aims to assess unlearning algorithms for:

- ğŸ”¥ Reducing malicious use in LLMs using **WMDP**
- ğŸ›¡ï¸ Preserving privacy by simulating personal data removal with **TOFU**

Applying **MUSE's comprehensive six-way evaluation**, covering:

- âœ… No verbatim memorization  
- âœ… No knowledge memorization  
- âœ… No privacy leakage  
- âœ… Utility preservation  
- âœ… Scalability  
- âœ… Sustainability  

---

## ğŸ“ Repository Under Development

The full codebase, datasets, and evaluation scripts will be organized to support experimentation and reproducibility. Stay tuned for updates.

---

